{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关联分析\n",
    "从大规模数据集中寻找物品间的隐含关系被称作关联分析（association analysis）或者关联规则学习（association rule learning）。\n",
    "\n",
    "这些关系可以有两种形式：频繁项集或者关联规则。频繁项集（frequent item sets）是经常出现在一块的物品的集合，关联规则（association rules）暗示两种物品之间可能存在很强的关系。\n",
    "\n",
    "支持度和可信度是被用来量化关联分析是否成功的方法。\n",
    "\n",
    "支持度：一个项集的支持度（support）被定义为数据集中包含该项集的记录所占的比例。支持度是针对项集来说的，因此可以定义一个最小支持度，而只保留满足最小支持度的项集。\n",
    "\n",
    "可信度或置信度（confidence）是针对一条诸如{A}->{B}的关联规则来定义的。这条规则的可信度被定义为\"支持度({A,B})/支持度({A})\"\n",
    "\n",
    "关联分析的目标：发现频繁项集和发现关联规则。首先需要找到频繁项集，然后才能获得关联规则。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apriori原理\n",
    "当有很多元素时，便会产生很多组合，为了计算每种组合的支持度以及可信度我们需要长时间的运算。为了降低运算时间，可以采用Apriori原理。\n",
    "\n",
    "Apriori原理:如果某个项集是频繁的，那么它的所有子集都是频繁的。\n",
    "\n",
    "直观上看这个原理并无帮助，但是反过来看，一个项集是非频繁集，那么它的所有超集也是非频繁的。\n",
    "\n",
    "Apriori算法是发现频繁项集的一种方法。输入最小支持度与数据集。算法先生成所有单个物品的项集列表。接着扫描交易记录来查看哪些项集满足最小支持度要求，那些不满足最小支持度的集合将被去掉。然后，对剩下的集合进行组合以生成包含两个元素的项集。接下来在重新扫描交易记录，去掉不满足最小支持度的项集。如此重复直至所有项集都被去掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T07:18:33.043312Z",
     "start_time": "2021-02-22T07:18:33.031242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1, 3, 4}, {2, 3, 5}, {1, 2, 3, 5}, {2, 5}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#辅助函数\n",
    "\n",
    "#数据集扫描伪代码\n",
    "#对数据集中的每条交易记录tran\n",
    "#对每个候选项集can：\n",
    "#    检查一下can是否是tran的子集：\n",
    "#    如果是，则增加can的计数值\n",
    "#对每个候选项集：\n",
    "#如果其支持度不低于最小值，则保留该项集\n",
    "#返回所有频繁项集列表\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "def loadDataSet():\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
    "\n",
    "#构建集合C1，C1是大小为1的所有候选项集的集合\n",
    "def createC1(dataSet):\n",
    "    C1 = []\n",
    "    for transaction in dataSet:#遍历记录\n",
    "        for item in transaction:#遍历记录中的每一项\n",
    "            if not [item] in C1:#如果该项并未出现在C1\n",
    "                C1.append([item])#这里是添加了项的一个列表 即意味着C1是一个集合的集合，如{{1},{2}...}\n",
    "    C1.sort()\n",
    "    return list(map(frozenset,C1)) #对C1中每个项构建一个不变集合  frozenset是python的一种数据类型，它们是不可变的\n",
    "\n",
    "#数据集扫描\n",
    "def scanD(D, Ck, minSupport):#数据集、包含候选集合的列表、最小支持度\n",
    "    ssCnt = {}\n",
    "    for tid in D:\n",
    "        for can in Ck:\n",
    "            if can.issubset(tid):\n",
    "                if can not in ssCnt: ssCnt[can]=1\n",
    "                else: ssCnt[can] += 1\n",
    "    numItems = float(len(list(D)))                 \n",
    "    retList = []\n",
    "    supportData = {}\n",
    "    for key in ssCnt:\n",
    "        support = ssCnt[key]/numItems #计算所有项集的支持度\n",
    "        if support >= minSupport:\n",
    "            retList.insert(0,key)\n",
    "        supportData[key] = support\n",
    "    return retList, supportData #返回频繁项集列表和频繁项集的支持度\n",
    "\n",
    "dataSet=loadDataSet()\n",
    "C1=createC1(dataSet)\n",
    "D = [set(var) for var in dataSet]\n",
    "print(D)\n",
    "L1,suppData0=scanD(D,C1,0.5)\n",
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T07:23:50.376941Z",
     "start_time": "2021-02-22T07:23:50.366541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[frozenset({2, 5}),\n",
       " frozenset({3, 5}),\n",
       " frozenset({1, 5}),\n",
       " frozenset({2, 3}),\n",
       " frozenset({1, 2}),\n",
       " frozenset({1, 3})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#完整Apriori算法\n",
    "#伪代码\n",
    "#当集合中项的个数大于0时\n",
    "#    构建一个k个项组成的候选项集的列表\n",
    "#    检查数据以确认每个项集都是频繁的\n",
    "#    保留频繁项集并构建k+1项组成的候选项集的列表\n",
    "\n",
    "def aprioriGen(Lk, k): #频繁项集列表、项集元素个数\n",
    "    retList = []\n",
    "    lenLk = len(Lk)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i+1, lenLk): \n",
    "            L1 = list(Lk[i])[:k-2]; L2 = list(Lk[j])[:k-2]\n",
    "            L1.sort(); L2.sort()\n",
    "            if L1==L2: #如果前k-2个项相同时，将两个集合合并\n",
    "                retList.append(Lk[i] | Lk[j]) \n",
    "    return retList#输出候选项集\n",
    "\n",
    "def apriori(dataSet, minSupport = 0.5):#数据集合、支持度\n",
    "    C1 = createC1(dataSet)\n",
    "    D = list(map(set, dataSet))\n",
    "    L1, supportData = scanD(D, C1, minSupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while (len(L[k-2]) > 0):\n",
    "        Ck = aprioriGen(L[k-2], k)\n",
    "        Lk, supK = scanD(D, Ck, minSupport)#扫描数据集 从Ck得到Lk 丢掉不满足最小支持度的项集\n",
    "        supportData.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "    return L, supportData\n",
    "\n",
    "#创建6个不重复的两元素集合\n",
    "L,supportData=apriori(dataSet)\n",
    "#print(L)#L包含满足最小支持度为0.5的频繁项集列表 每个项集都是函数apriori调用aprioriGen()来的\n",
    "\n",
    "#aprioriGen函数工作过程\n",
    "print(L[0])\n",
    "aprioriGen(L[0],2)\n",
    "\n",
    "#在70%支持度的输出\n",
    "#L,supportData=apriori(dataSet,minSupport=0.7)\n",
    "#L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**通过上述函数，我们可以发现频繁项集，现在需要从其中找出关联规则**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T08:10:44.859060Z",
     "start_time": "2021-02-22T08:10:44.844886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({5}) --> frozenset({2}) conf: 1.0\n",
      "frozenset({2}) --> frozenset({5}) conf: 1.0\n",
      "frozenset({1}) --> frozenset({3}) conf: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(frozenset({5}), frozenset({2}), 1.0),\n",
       " (frozenset({2}), frozenset({5}), 1.0),\n",
       " (frozenset({1}), frozenset({3}), 1.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#关联规则生成函数\n",
    "\n",
    "#主函数\n",
    "def generateRules(L, supportData, minConf=0.7):  #频繁项集列表、包含那些频繁项集支持数据的字典、最小可信度阈值\n",
    "    bigRuleList = []\n",
    "    for i in range(1, len(L)):#只获取有两个或更多元素的集合\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            if (i > 1):#如果频繁项集元素数目大于2，则通过一下函数对其进行合并\n",
    "                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "            else:#不然则计算可信度值\n",
    "                calcConf(freqSet, H1, supportData, bigRuleList, minConf)\n",
    "    return bigRuleList #包含可信度的规则列表    \n",
    "\n",
    "#生成候选规则集合\n",
    "def calcConf(freqSet, H, supportData, brl, minConf=0.7):\n",
    "    prunedH = [] \n",
    "    for conseq in H:#变量H中所有项集并计算器可信度\n",
    "        conf = supportData[freqSet]/supportData[freqSet-conseq] #计算可信度\n",
    "        if conf >= minConf: #如果某条规则满足最小可信度值，那么输出该规则\n",
    "            print(freqSet-conseq,'-->',conseq,'conf:',conf)\n",
    "            brl.append((freqSet-conseq, conseq, conf))\n",
    "            prunedH.append(conseq)\n",
    "    return prunedH #返回一个满足最小可信度要求的规则列表\n",
    "\n",
    "#对规则进行评估\n",
    "def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7):#频繁项集、可以出现在规则右部的元素列表H\n",
    "    m = len(H[0])#H中频繁项集列表大小\n",
    "    if (len(freqSet) > (m + 1)): #检查频繁项集是否大到可以移除大小为m的子集\n",
    "        Hmp1 = aprioriGen(H, m+1)#生成H中元素的无重复组合 即创建Hm+1条新候选规则\n",
    "        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)#Hmp1包含所有可能的规则。利用calcConf()来测试它们的可信度以确定规则是否满足要求\n",
    "        if (len(Hmp1) > 1):    #如果不止一条规则满足要求\n",
    "            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)#继续调用，判断是否可以进一步组合这些规则\n",
    "            \n",
    "L,supportData=apriori(dataSet,minSupport=0.5)\n",
    "rules=generateRules(L,supportData,minConf=0.7)\n",
    "#rules=generateRules(L,supportData,minConf=0.5)降低可信度阈值会获得更多的规则\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "关联分析是用于发现大数据集中元素关系的一个工具集，可以采用两种方式来量化这些有趣的关系：\n",
    "* 使用频繁项集，它会给出经常在一起出现的元素项\n",
    "* 关联规则，每条关联规则意味着元素项之间的“如果......那么”关系\n",
    "\n",
    "Apriori算法优缺点：\n",
    "* 优点：易编码实现\n",
    "* 缺点：在大数据集上可能较慢\n",
    "* 适用数据类型：数值型或者标称型数据\n",
    "\n",
    "因为每次增加频繁项集的大小，Apriori算法都会重新扫描整个数据集。当数据集很大时，就会比较慢。在此引入FPgrowth算法，该算法只需要对数据库进行两次遍历，能够显著加快发现频繁项集的速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP-growth算法\n",
    "它基于Apriori构建，但采用了一些不同的技术。将数据集存储在一个特定的称作FP树的结构之后发现频繁项集或频繁项对，即常在一块出现的元素项的集合FP树\n",
    "\n",
    "FP-growth算法会扫描数据集两次，它发现频繁项集的基本过程如下：\n",
    "1. 构建FP树\n",
    "2. 从FP树中挖掘频繁项集\n",
    "\n",
    "FP（Frequent Pattern）代表频繁模式。FP树通过链接（link）来连接相似元素。\n",
    "\n",
    "关于FP树：https://www.cnblogs.com/zhengxingpeng/p/6679280.html\n",
    "\n",
    "FP-growth算法对原始数据扫描两次：第一遍用来统计出现的频率，第二遍扫描中只考虑那些频繁元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T12:15:58.229884Z",
     "start_time": "2021-02-22T12:15:58.222756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pyramid   9\n",
      "     eye   13\n",
      "     phoenix   3\n"
     ]
    }
   ],
   "source": [
    "class treeNode:\n",
    "    #存放节点名字的变量和1个计数值\n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue\n",
    "        self.count = numOccur\n",
    "        self.nodeLink = None #nodeLink用于链接相似的元素\n",
    "        self.parent = parentNode      #指向父节点\n",
    "        self.children = {} \n",
    "    \n",
    "    def inc(self, numOccur):#对count变量增加给定量\n",
    "        self.count += numOccur\n",
    "        \n",
    "    def disp(self, ind=1):#将树以文本形式显示\n",
    "        print('  '*ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind+1)\n",
    "            \n",
    "rootNode=treeNode('pyramid',9,None)\n",
    "rootNode.children['eye']=treeNode('eye',13,None)\n",
    "rootNode.children['phoenix']=treeNode('phoenix',3,None)\n",
    "rootNode.disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T12:34:39.358489Z",
     "start_time": "2021-02-22T12:34:39.342247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Null Set   1\n",
      "     z   5\n",
      "       r   1\n",
      "       x   3\n",
      "         s   2\n",
      "           y   2\n",
      "             t   2\n",
      "         r   1\n",
      "           y   1\n",
      "             t   1\n",
      "     x   1\n",
      "       r   1\n",
      "         s   1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def createTree(dataSet, minSup=1): #使用数据集记最小支持度作为参数构建FP树\n",
    "    headerTable = {}\n",
    "    #遍历两次数据集\n",
    "    for trans in dataSet:#扫描数据集，并统计各个元素项出现的频度\n",
    "        for item in trans:\n",
    "            headerTable[item] = headerTable.get(item, 0) + dataSet[trans]\n",
    "    for k in list(headerTable.keys()):  #移除不满足最小支持度的元素项\n",
    "        if headerTable[k] < minSup: \n",
    "            del(headerTable[k])\n",
    "    freqItemSet = set(headerTable.keys())\n",
    "    #print('freqItemSet: ',freqItemSet)\n",
    "    if len(freqItemSet) == 0: return None, None  #如果没有元素项满足，则退出\n",
    "    for k in headerTable:\n",
    "        headerTable[k] = [headerTable[k], None] #扩展头指针表以便报错计数值及指向每种类型第一个元素项的指针\n",
    "    #print('headerTable: ',headerTable)\n",
    "    retTree = treeNode('Null Set', 1, None) #建树\n",
    "    for tranSet, count in dataSet.items():  #再一次遍历数据集，这次只考虑那些频繁项\n",
    "        localD = {}\n",
    "        for item in tranSet:  #根据全局频率对每个事务中的元素进行排序\n",
    "            if item in freqItemSet:\n",
    "                localD[item] = headerTable[item][0]\n",
    "        if len(localD) > 0:\n",
    "            orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p: p[1], reverse=True)]\n",
    "            updateTree(orderedItems, retTree, headerTable, count)#使用排序后的频繁项集对树进行填充\n",
    "    return retTree, headerTable #返回树和头指针表\n",
    "\n",
    "#用于让树生长，输入参数为一个项集\n",
    "def updateTree(items, inTree, headerTable, count):\n",
    "    if items[0] in inTree.children:#首先测试事务中的第一个元素项是否作为子节点存在\n",
    "        inTree.children[items[0]].inc(count) #如果存在，则更新该元素项的计数\n",
    "    else:   #不存在则创建一个新的treenode并将其作为子节点添加到树中\n",
    "        inTree.children[items[0]] = treeNode(items[0], count, inTree)\n",
    "        if headerTable[items[0]][1] == None: #更新头指针表\n",
    "            headerTable[items[0]][1] = inTree.children[items[0]]\n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]][1], inTree.children[items[0]])\n",
    "    if len(items) > 1:#不断迭代调用自身，每次调用会去掉列表的第一个元素\n",
    "        updateTree(items[1::], inTree.children[items[0]], headerTable, count)\n",
    "\n",
    "#用于确保节点链接指向树中该元素项的每一个实例\n",
    "def updateHeader(nodeToTest, targetNode):   \n",
    "    while (nodeToTest.nodeLink != None):    #不要使用递归遍历链表，因为如果链表很长会遇到迭代调用的次数限制\n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    nodeToTest.nodeLink = targetNode\n",
    "    \n",
    "    \n",
    "    \n",
    "#数据集与建树\n",
    "def loadSimpDat():\n",
    "    simpDat = [['r', 'z', 'h', 'j', 'p'],\n",
    "               ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'],\n",
    "               ['z'],\n",
    "               ['r', 'x', 'n', 'o', 's'],\n",
    "               ['y', 'r', 'x', 'z', 'q', 't', 'p'],\n",
    "               ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']]\n",
    "    return simpDat\n",
    "\n",
    "def createInitSet(dataSet):\n",
    "    retDict = {}\n",
    "    for trans in dataSet:\n",
    "        retDict[frozenset(trans)] = 1\n",
    "    return retDict\n",
    "\n",
    "simpDat=loadSimpDat()\n",
    "initSet=createInitSet(simpDat)\n",
    "myFPtree,myHeaderTab=createTree(initSet,3)\n",
    "myFPtree.disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建好树之后就是抽取频繁项集，步骤如下：\n",
    "1. 从FP树中获得条件模式基\n",
    "2. 利用条件模式基，构建一个条件FP树\n",
    "3. 迭代重复步骤（1）步骤（2），直到树包含一个元素项为止\n",
    "\n",
    "条件模式基（conditional pattern base）是以所查找元素项为结尾的路径集合。每一条路径其实都是一条前缀路径（prefix path）。一条前缀路径是介于所查找元素项与树根节点之间的所有内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T12:43:06.905573Z",
     "start_time": "2021-02-22T12:43:06.894485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'z'}): 3}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#发现以给定元素项结尾的所有路径的函数\n",
    "\n",
    "def ascendTree(leafNode, prefixPath): #迭代上溯整棵树\n",
    "    if leafNode.parent != None:\n",
    "        prefixPath.append(leafNode.name)\n",
    "        ascendTree(leafNode.parent, prefixPath)\n",
    "    \n",
    "def findPrefixPath(basePat, treeNode): #遍历链表知直到到达结尾\n",
    "    condPats = {}\n",
    "    while treeNode != None: #每遇到一个元素就调用ascendTree()来上溯FP树，并收集所有遇到的元素项的名称\n",
    "        prefixPath = []\n",
    "        ascendTree(treeNode, prefixPath)\n",
    "        if len(prefixPath) > 1: \n",
    "            condPats[frozenset(prefixPath[1:])] = treeNode.count\n",
    "        treeNode = treeNode.nodeLink\n",
    "    return condPats #条件模式基字典\n",
    "\n",
    "\n",
    "findPrefixPath('x',myHeaderTab['x'][1])\n",
    "#findPrefixPath('x',myHeaderTab['z'][1])\n",
    "#findPrefixPath('x',myHeaderTab['r'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现上述的返回值与表中结果一致。有了条件模式基之后，就可以创建条件FP树。对于每个频繁项集，都要创建一棵条件FP树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-22T12:52:37.837406Z",
     "start_time": "2021-02-22T12:52:37.829414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'r'},\n",
       " {'s'},\n",
       " {'s', 'x'},\n",
       " {'y'},\n",
       " {'x', 'y'},\n",
       " {'y', 'z'},\n",
       " {'x', 'y', 'z'},\n",
       " {'t'},\n",
       " {'t', 'y'},\n",
       " {'t', 'z'},\n",
       " {'t', 'y', 'z'},\n",
       " {'t', 'x'},\n",
       " {'t', 'x', 'y'},\n",
       " {'t', 'x', 'z'},\n",
       " {'t', 'x', 'y', 'z'},\n",
       " {'x'},\n",
       " {'x', 'z'},\n",
       " {'z'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#递归查找频繁项集的函数\n",
    "def mineTree(inTree, headerTable, minSup, preFix, freqItemList):\n",
    "    bigL = [v[0] for v in sorted(headerTable.items(), key=lambda p: p[1][0])]#对头指针表中的元素项按照其出现频率进行排序（默认从小到大）\n",
    "    for basePat in bigL:\n",
    "        newFreqSet = preFix.copy()\n",
    "        newFreqSet.add(basePat)\n",
    "        #print('finalFrequent Item: ',newFreqSet)   #append to set\n",
    "        freqItemList.append(newFreqSet)\n",
    "        condPattBases = findPrefixPath(basePat, headerTable[basePat][1])#  #递归调用创建条件基\n",
    "        #print('condPattBases :',basePat, condPattBases)\n",
    "        myCondTree, myHead = createTree(condPattBases, minSup)#该条件基被作为新数据传递给createTree函数 从条件模式基来构建条件FP树\n",
    "        #print('head from conditional tree: ', myHead)\n",
    "        if myHead != None: #挖掘条件FP树\n",
    "            #print('conditional tree for: ',newFreqSet)\n",
    "            #myCondTree.disp(1)            \n",
    "            mineTree(myCondTree, myHead, minSup, newFreqSet, freqItemList) #如果树中有元素项的话，递归调用mineTree()\n",
    "\n",
    "freqItems=[]\n",
    "mineTree(myFPtree,myHeaderTab,3,set([]),freqItems)\n",
    "freqItems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "FP-growth优缺点\n",
    "* 优点：一般要快于Apriori\n",
    "* 缺点：实现比较困难，在某些数据集上性能会下降\n",
    "* 适用数据类型：标称型数据"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
