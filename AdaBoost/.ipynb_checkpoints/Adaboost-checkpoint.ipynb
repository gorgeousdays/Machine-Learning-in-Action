{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原理\n",
    "元算法（meta-algorithm）是对其它算法进行组合的一种方式\n",
    "Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。\n",
    "Boosting，也称为增强学习或提升法，是一种元算法框架，而AdaBoost是其中最成功的代表。\n",
    "\n",
    "AdaBoost为每个分类器都分配一个权重值alpha，alpha基于每个弱分类器的错误率进行计算。\n",
    "$$\\varepsilon=\\frac{未正确分类的样本数目}{所有样本数目}$$\n",
    "而alpha为\n",
    "$$\\alpha=\\frac{1}{2}ln(\\frac{1-\\varepsilon}{\\varepsilon})$$\n",
    "计算出alpha后可以对权重向量D进行更新，以使得那些正确分类的样本的权重降低而错分样本的权重升高。\n",
    "\n",
    "如果某个样本被正确分类，则其权重调整为$$D_i^{(t+1)}=\\frac{D_i^{(t)}e^{-\\alpha}}{Sum(D)}$$\n",
    "如果某个样本被错误分类，则其权重调整为$$D_i^{(t+1)}=\\frac{D_i^{(t)}e^{\\alpha}}{Sum(D)}$$\n",
    "计算出D后，AdaBoost进行下一次迭代。不断重复训练直至错误率为0或者弱分类器数目达到指定值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T07:29:31.921875Z",
     "start_time": "2021-02-16T07:29:31.052084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "datMat = matrix([[ 1. ,  2.1],\n",
    "        [ 1.5,  1.6],\n",
    "        [ 1.3,  1. ],\n",
    "        [ 1. ,  1. ],\n",
    "        [ 2. ,  1. ]])\n",
    "classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "\n",
    "\n",
    "xcord0 = []\n",
    "ycord0 = []\n",
    "xcord1 = []\n",
    "ycord1 = []\n",
    "markers =[]\n",
    "colors =[]\n",
    "\n",
    "for i in range(len(classLabels)):\n",
    "    if classLabels[i]==1.0:\n",
    "        xcord1.append(datMat[i,0]), ycord1.append(datMat[i,1])\n",
    "    else:\n",
    "        xcord0.append(datMat[i,0]), ycord0.append(datMat[i,1])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)       \n",
    "ax.scatter(xcord0,ycord0, marker='s', s=90)\n",
    "ax.scatter(xcord1,ycord1, marker='o', s=50, c='red')\n",
    "plt.title('decision stump test data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对于以上的数据类型，很难选择一条与坐标轴平行的直线将两种数据点分开，这就意味着单层决策树很难处理，通过使用多棵单层决策树，我们就可以构建出一个很好的分类器。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T07:22:37.003778Z",
     "start_time": "2021-02-17T07:22:36.980332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'ineq': 'lt'},\n",
       " matrix([[0.2]]),\n",
       " array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#单层决策树生成函数（弱分类算法）\n",
    "#伪代码\n",
    "#将最小错误率minError设为正无穷\n",
    "#对数据集中的每一个特征（第一层循环）：\n",
    "#    对每个步长（第二层循环）：\n",
    "#        对每个不等号（第三层循环）：\n",
    "#            建立一棵单层决策树并利用加权数据集对它进行测试\n",
    "#            如果错误率低于minError，则将当前单层决策树设为最佳单层决策树\n",
    "#返回最佳单层决策树\n",
    "from numpy import *\n",
    "\n",
    "def loadSimpData():\n",
    "    datMat = matrix([[ 1. ,  2.1],\n",
    "        [ 2. ,  1.1],\n",
    "        [ 1.3,  1. ],\n",
    "        [ 1. ,  1. ],\n",
    "        [ 2. ,  1. ]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return datMat,classLabels\n",
    "\n",
    "def loadDataSet(fileName):      #general function to parse tab -delimited floats\n",
    "    numFeat = len(open(fileName).readline().split('\\t')) #get number of fields \n",
    "    dataMat = []; labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr =[]\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat,labelMat\n",
    "\n",
    "#通过预祝比较对数据进行分类，在阈值一边的数据为类别-1，另外一边为+1\n",
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq):\n",
    "    retArray = ones((shape(dataMatrix)[0],1))#将返回数组的全部元素设置为1\n",
    "    if threshIneq == 'lt':#将不满足要求的设为-1\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "    \n",
    "\n",
    "def buildStump(dataArr,classLabels,D):#传入数据、类别、权重向量\n",
    "    dataMatrix = mat(dataArr); labelMat = mat(classLabels).T\n",
    "    m,n = shape(dataMatrix)\n",
    "    numSteps = 10.0; bestStump = {}; bestClasEst = mat(zeros((m,1)))\n",
    "    minError = inf #一开始初始化为无穷大 之后用于寻找可能的最小错误率\n",
    "    for i in range(n):#在数据集的所有特征上变量\n",
    "        rangeMin = dataMatrix[:,i].min(); rangeMax = dataMatrix[:,i].max();#获取最大值与最小值\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps#通过最大值与最小值计算步长\n",
    "        for j in range(-1,int(numSteps)+1):#在这些值上遍历\n",
    "            for inequal in ['lt', 'gt']: #在大于小于间切换不等号\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)#调用函数，基于这些循环变量，函数会返回分类预测的结果\n",
    "                errArr = mat(ones((m,1))) #将errArr全部初始化为1，也就是说全错\n",
    "                errArr[predictedVals == labelMat] = 0  #如果说预测值与真实值相等，那么该位置对应的errArr就是0，也就是说该位置时对的\n",
    "                weightedError = D.T*errArr  #c权重向量与错误向量相乘\n",
    "                #print(\"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError))\n",
    "                #如果当前错误率比最小错误率小，则保存当前单层决策树\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump,minError,bestClasEst\n",
    "\n",
    "datMat,classLabels=loadSimpData()\n",
    "D=mat(ones((5,1))/5)#权重向量\n",
    "buildStump(datMat,classLabels,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T07:23:49.100652Z",
     "start_time": "2021-02-17T07:23:49.077714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error:  0.2\n",
      "total error:  0.2\n",
      "total error:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453},\n",
       " {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#基于以上的基于加权输入值进行决策的分类器（弱分类器），我们可以实现一个完整AdaBoost算法(强分类器)\n",
    "#伪代码\n",
    "#对每次迭代：\n",
    "#    利用buildStump（）函数找到最佳的单层决策树\n",
    "#    将最佳单层决策树加入到单层决策树数组\n",
    "#    计算alpha\n",
    "#    计算新的权重向量D\n",
    "#    更新累计类别估计向量\n",
    "#    如果错误率等于0.0，则退出循环\n",
    "\n",
    "#基于单层决策树的AdaBoost的训练过程\n",
    "def adaBoostTrainDS(dataArr,classLabels,numIt=40):  #数据集、类别标签、迭代次数\n",
    "    weakClassArr = []\n",
    "    m = shape(dataArr)[0]\n",
    "    D = mat(ones((m,1))/m)   #D表示各个数据点的权重，它是一个概率分布向量，即其所有元素之和为0,开始初始化每个权重为1/m\n",
    "    aggClassEst = mat(zeros((m,1)))#用于记录每个数据点的类别估计累计值\n",
    "    for i in range(numIt):#循环会在错误率为0或者达到迭代次数时停止\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D)#创建单层决策树\n",
    "        #print(\"D:\",D.T)\n",
    "        alpha = float(0.5*log((1.0-error)/max(error,1e-16)))#alpha用于告诉总分类器本次单层决策树输出结果的权重，max（error，1e-16）用于确保不会发生除0溢出\n",
    "        bestStump['alpha'] = alpha  #alpha值加入besttump字典\n",
    "        weakClassArr.append(bestStump)                 # 字典加入列表，该字典包含分类所需的所有信息\n",
    "        #print(\"classEst: \",classEst.T)\n",
    "        expon = multiply(-1*alpha*mat(classLabels).T,classEst) #用于计算下一次迭代的新权重向量D\n",
    "        D = multiply(D,exp(expon))                              \n",
    "        D = D/D.sum()\n",
    "        aggClassEst += alpha*classEst\n",
    "        #print(\"aggClassEst: \",aggClassEst.T)\n",
    "        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,1)))#由于aggClassEst是一个浮点数，，为了得到二值分类结果，调用sign函数\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print(\"total error: \",errorRate)\n",
    "        if errorRate == 0.0: break #总错误率为0 则终止for循环\n",
    "    return weakClassArr,aggClassEst#权重值、类别估计值\n",
    "classifierArray,aggClassEst=adaBoostTrainDS(datMat,classLabels,9)\n",
    "classifierArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoostTrainDS函数中DS代表单层决策树(decision stump)，它是AdaBoost中最流行的弱分类器。除此之外，其它的分类器都可以作为基分类器。**\n",
    "\n",
    "**以上输出的数组包含三部字典，其中包含了分类所需的全部信息，分类器构建成功,而后我们将各个弱分类器的结果抽离出来，以其对应的alpha作为权重。所有这些弱分类器的结果加权求和得到最后结果。代码如下：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-17T07:26:31.721396Z",
     "start_time": "2021-02-17T07:26:31.707432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error:  0.2\n",
      "total error:  0.2\n",
      "total error:  0.0\n",
      "{'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565}\n",
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n",
      "[[-2.56198199]]\n",
      "[[-1.]]\n",
      "{'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565}\n",
      "[[ 0.69314718]\n",
      " [-0.69314718]]\n",
      "[[ 1.66610226]\n",
      " [-1.66610226]]\n",
      "[[ 2.56198199]\n",
      " [-2.56198199]]\n",
      "[[ 1.]\n",
      " [-1.]]\n"
     ]
    }
   ],
   "source": [
    "def adaClassify(datToClass,classifierArr):\n",
    "    dataMatrix = mat(datToClass)\n",
    "    m = shape(dataMatrix)[0]\n",
    "    aggClassEst = mat(zeros((m,1)))\n",
    "    print(classifierArr[1])\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],classifierArr[i]['thresh'],classifierArr[i]['ineq'])#\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst#弱分类器结果加权求和得到结果\n",
    "        print(aggClassEst)\n",
    "    return sign(aggClassEst)\n",
    "datArr,labelArr=loadSimpData()\n",
    "classifierArr,aggClassEst=adaBoostTrainDS(datArr,labelArr,30)\n",
    "print(adaClassify([0,0],classifierArr))#传入一个点时分类结果\n",
    "print(adaClassify([[5,5],[0,0]],classifierArr))#传入两个点时分类结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非均衡分类问题\n",
    "通过错误率来来衡量分类器的成功程度。错误率指得是在所有测试样例中错分的样例比例。但这样度量错误掩盖了样例如何被错分的事实。通过混淆矩阵可以便于人们了解分类中的错误。以下是一个二类问题的混淆矩阵。\n",
    "\n",
    "|  |   |预测结果|预测结果|\n",
    "| ------ | ------ | ------ |------|\n",
    "|  |  |+1 |-1|\n",
    "| 真实结果 | +1 | 真正例（TP）|伪反例（FN）|\n",
    "| 真实结果 | -1 | 伪正例（FP） |真反例（TN）|\n",
    "\n",
    "我们期望混淆矩阵的非对角元素均为0，这时就会得到一个完美的分类器。\n",
    "\n",
    "通过混淆矩阵，我们可以定义出比错误率更好的新指标，如：\n",
    "* 正确率（Precision）=TP/(TP+FP) 预测为正例的样本中真正正例的比例\n",
    "* 召回率（Recall）=TP/(TP+FN)  预测为正例的真实正例占所有真实正例的比例\n",
    "\n",
    "除此之外，另一个用于度量分类中的非均衡性的工具是ROC曲线，ROC代表接受者操作特征（receiver operating characteristic）。可用于比较分类器，还可以基于成本效益（cost-versus-benefit）分析做出决策。在此不过多介绍ROC曲线，它的作用就是对分类器的效果做出评判。\n",
    "\n",
    "处理非均匀分类代价问题的方法：\n",
    "* 调节分类器的阈值\n",
    "* 代价敏感的学习（cost-sensitive learing）\n",
    "* 对分类器的训练数据进行改造。这可以通过欠抽样（undersampling）或者过抽样（oversampling）来实现。过抽样意味着复制样例，欠抽样意味着删除样例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "两种集成方法bagging和boosting。在bagging中，是通过随机抽样的替换方式，得到了与原始数据集规模一样的数据集。而boosting在bagging的思路上更近一步，在数据集上顺序应用了多个不同的分类器。集成方法有随机森林和AdaBoosting等。而boosting方法中最流行的是AdaBoosting算法。\n",
    "AdaBoost优缺点：\n",
    "* 优点：泛化错误率低，易编码，可以应用在大部分分类器上，无参数调整。\n",
    "* 缺点：对离群点敏感。\n",
    "* 适用数据类型：数值型和标称型数据。\n",
    "\n",
    "AdaBoost算法流程\n",
    "1. 先通过对N个训练样本的学习得到第一个弱分类器；\n",
    "2. 将分错的样本和其他的新数据一起构成一个新的N个的训练样本，通过对这个样本的学习得到第二个弱分类器 ；\n",
    "3. 将1和2都分错了的样本加上其他的新样本构成另一个新的N个的训练样本，通过对这个样本的学习得到第三个弱分类器；\n",
    "4. 最终经过提升的强分类器。即某个数据被分为哪一类要由各分类器权值决定。\n",
    "\n",
    "AdaBoost系列主要解决了: 两类问题、多类单标签问题、多类多标签问题、大类单标签问题、回归问题。它用全部的训练样本进行学习。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
